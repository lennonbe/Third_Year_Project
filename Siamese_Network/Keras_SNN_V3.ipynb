{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Keras_SNN_V3.ipynb","provenance":[],"mount_file_id":"1_GD6YVAUmshY8Z8CK1iNtzxTH7x-R8bx","authorship_tag":"ABX9TyNbdFRonSxcJPxyswcVjNGs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"hkCqbtizzPvc","executionInfo":{"status":"ok","timestamp":1641127322398,"user_tz":0,"elapsed":2846,"user":{"displayName":"Daniel Lennon Beato","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEJRsxk3v-ST_AHEFSN7dmbqrTIr81izMUeQKP_w=s64","userId":"10725049979396702399"}}},"outputs":[],"source":["#Import dependencies\n","import cv2\n","from PIL import Image\n","import os\n","import random\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","#Import tensorflow dependencies\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow import keras\n","from tensorflow.keras import layers\n"]},{"cell_type":"code","source":["def make_embedding():\n","    input = Input(shape=(224,224,3), name='flood_image')\n","\n","    #First convulutional layer\n","    c1 = Conv2D(64, (10,10), activation='relu')(input)\n","    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n","\n","    #Second convulutional layer\n","    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n","    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n","\n","    #Third and final convulutional layer\n","    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n","    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n","\n","    #Final layer\n","    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n","    f1 = Flatten()(c4)\n","    d1 = Dense(4096, activation='sigmoid')(f1)\n","\n","    return Model(inputs=[input], outputs=[d1], name='embedding')"],"metadata":{"id":"bn0fm264zY0X","executionInfo":{"status":"ok","timestamp":1641127322398,"user_tz":0,"elapsed":3,"user":{"displayName":"Daniel Lennon Beato","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEJRsxk3v-ST_AHEFSN7dmbqrTIr81izMUeQKP_w=s64","userId":"10725049979396702399"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["embedding = make_embedding()\n","embedding.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySUKy-wdzcrQ","executionInfo":{"status":"ok","timestamp":1641127331025,"user_tz":0,"elapsed":8629,"user":{"displayName":"Daniel Lennon Beato","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEJRsxk3v-ST_AHEFSN7dmbqrTIr81izMUeQKP_w=s64","userId":"10725049979396702399"}},"outputId":"28b92ecf-6b2a-4205-adf5-a70191d5d730"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"embedding\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flood_image (InputLayer)    [(None, 224, 224, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 215, 215, 64)      19264     \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 108, 108, 64)     0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 102, 102, 128)     401536    \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 51, 51, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 48, 48, 128)       262272    \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 24, 24, 128)      0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 21, 21, 256)       524544    \n","                                                                 \n"," flatten (Flatten)           (None, 112896)            0         \n","                                                                 \n"," dense (Dense)               (None, 4096)              462426112 \n","                                                                 \n","=================================================================\n","Total params: 463,633,728\n","Trainable params: 463,633,728\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Siamese L1 Distance class\n","class L1Dist(Layer):\n","    \n","    # Init method - inheritance\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","       \n","    # Similarity calculation\n","    def call(self, input_embedding, validation_embedding):\n","        return tf.math.abs(input_embedding - validation_embedding)"],"metadata":{"id":"67vyIGr-zewk","executionInfo":{"status":"ok","timestamp":1641127331026,"user_tz":0,"elapsed":4,"user":{"displayName":"Daniel Lennon Beato","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEJRsxk3v-ST_AHEFSN7dmbqrTIr81izMUeQKP_w=s64","userId":"10725049979396702399"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def make_siamese_model(): \n","    \n","    # Anchor image input in the network\n","    input_image = Input(name='input_img', shape=(224,224,3))\n","    \n","    # Validation image in the network \n","    validation_image = Input(name='validation_img', shape=(224,224,3))\n","    \n","    # Combine siamese distance components\n","    siamese_layer = L1Dist()\n","    siamese_layer._name = 'distance'\n","    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n","    \n","    # Classification layer \n","    classifier = Dense(1, activation='sigmoid')(distances)\n","    \n","    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"],"metadata":{"id":"KW6MmESazgtM","executionInfo":{"status":"ok","timestamp":1641127331026,"user_tz":0,"elapsed":3,"user":{"displayName":"Daniel Lennon Beato","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEJRsxk3v-ST_AHEFSN7dmbqrTIr81izMUeQKP_w=s64","userId":"10725049979396702399"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Setup paths\n","CORE_PATH = '/content/drive/MyDrive/Third_Year_Project/Siamese_Network/Data_Pre_Processing_Siamese/Data_Final'\n","TRUE_PAIRINGS = '/content/drive/MyDrive/Third_Year_Project/Siamese_Network/Data_Pre_Processing_Siamese/Data_Final/Image_Pairs_Equal'\n","FALSE_PAIRINGS = '/content/drive/MyDrive/Third_Year_Project/Siamese_Network/Data_Pre_Processing_Siamese/Data_Final/Image_Pairs'\n","\n","def preprocess(file_path):\n","    \n","    # Read in image from file path\n","    byte_img = tf.io.read_file(file_path)\n","    # Load in the image \n","    img = tf.io.decode_jpeg(byte_img)\n","    \n","    # Preprocessing steps - resizing the image to be 224x224x3\n","    img = tf.image.resize(img, (224,224))\n","    # Scale image to be between 0 and 1 \n","    img = img / 255.0\n","\n","    # Return image\n","    return img\n","\n","def preprocess_twin(input_img, validation_img):\n","    return(preprocess(input_img), preprocess(validation_img))"],"metadata":{"id":"yafG75HWzk1Z","executionInfo":{"status":"ok","timestamp":1641128053188,"user_tz":0,"elapsed":333,"user":{"displayName":"Daniel Lennon Beato","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEJRsxk3v-ST_AHEFSN7dmbqrTIr81izMUeQKP_w=s64","userId":"10725049979396702399"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["img_height = 224\n","img_width = 224\n","channels = 3\n","batch_size = 10\n","\n","ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n","    CORE_PATH,\n","    labels=\"inferred\",\n","    label_mode=\"int\",  # categorical, binary\n","    # class_names=['0', '1', '2', '3', ...]\n","    color_mode=\"rgb\",\n","    batch_size=batch_size,\n","    image_size=(img_height, img_width),  # reshape if not in this size\n","    shuffle=True,\n","    seed=123,\n","    validation_split=0.1,\n","    subset=\"training\",\n",")\n","\n","print('-----------------------------------------------------------')\n","\n","ds_validation = tf.keras.preprocessing.image_dataset_from_directory(\n","    CORE_PATH,\n","    labels=\"inferred\",\n","    label_mode=\"int\",  # categorical, binary\n","    # class_names=['0', '1', '2', '3', ...]\n","    color_mode=\"rgb\",\n","    batch_size=batch_size,\n","    image_size=(img_height, img_width),  # reshape if not in this size\n","    shuffle=True,\n","    seed=123,\n","    validation_split=0.1,\n","    subset=\"training\",\n",")\n","\n","print('-----------------------------------------------------------')\n","\n","print(ds_train)\n","\n","#samples = ds_train.as_numpy_iterator()\n","\n","#print(samples.next())\n","\n","#ds_train = ds_train.map(preprocess_twin)\n","\n","# Custom Loops\n","for epochs in range(10):\n","    for x, y in ds_train:   \n","        print(x)\n","        print('-------------------------------')\n","        print(y)\n","        break\n","\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPuFvnx30GeO","executionInfo":{"status":"ok","timestamp":1641128716429,"user_tz":0,"elapsed":4119,"user":{"displayName":"Daniel Lennon Beato","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiEJRsxk3v-ST_AHEFSN7dmbqrTIr81izMUeQKP_w=s64","userId":"10725049979396702399"}},"outputId":"ab1e8760-1e47-4224-a36d-781e2e069d28"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1074 files belonging to 2 classes.\n","Using 967 files for training.\n","-----------------------------------------------------------\n","Found 1074 files belonging to 2 classes.\n","Using 967 files for training.\n","-----------------------------------------------------------\n","<BatchDataset shapes: ((None, 224, 224, 3), (None,)), types: (tf.float32, tf.int32)>\n","tf.Tensor(\n","[[[[168.04593   168.15306   174.67857  ]\n","   [202.56633   193.4847    191.08163  ]\n","   [172.83163   188.13266   195.20918  ]\n","   ...\n","   [ 87.52057    59.93373    62.561325 ]\n","   [120.15297    69.41835    76.77576  ]\n","   [172.42944   136.61241   120.54762  ]]\n","\n","  [[202.46939   195.09184   190.43878  ]\n","   [212.65817   205.04083   197.96939  ]\n","   [178.5357    183.87753   188.18367  ]\n","   ...\n","   [155.38362    85.25542   105.42412  ]\n","   [ 98.11213    82.50506    78.97956  ]\n","   [141.32788   114.04697   105.17947  ]]\n","\n","  [[192.82654   189.04593   183.31122  ]\n","   [217.5       214.44897   210.38776  ]\n","   [120.13776   126.73469   153.47958  ]\n","   ...\n","   [ 93.464386   78.7398     78.372536 ]\n","   [162.37769   149.23999   142.73985  ]\n","   [ 98.63128    90.58001   101.800766 ]]\n","\n","  ...\n","\n","  [[143.38724   159.77003   147.65799  ]\n","   [151.85677   136.06116   163.02602  ]\n","   [158.57101   149.16783   152.34166  ]\n","   ...\n","   [121.70872    94.8661    116.56516  ]\n","   [130.26524   135.65765   159.33124  ]\n","   [166.40327   188.99516   191.76566  ]]\n","\n","  [[166.29066   176.44348   174.55089  ]\n","   [101.08177    99.21968   119.56126  ]\n","   [147.04128   152.0465    180.9288   ]\n","   ...\n","   [145.80054   139.77985   153.43811  ]\n","   [145.86751   141.77618   166.55623  ]\n","   [136.19489   143.6854    154.30258  ]]\n","\n","  [[132.76576   111.14765   120.27518  ]\n","   [105.923706   70.1424     79.70392  ]\n","   [150.20906   161.68289   179.56534  ]\n","   ...\n","   [135.40854   129.82578   148.56122  ]\n","   [162.6784    175.61694   191.38254  ]\n","   [198.86156   206.33047   206.99934  ]]]\n","\n","\n"," [[[197.54082   185.02551   179.35204  ]\n","   [228.17348   222.66327   219.16327  ]\n","   [214.28061   207.22449   201.69897  ]\n","   ...\n","   [209.57784   201.75139   192.85826  ]\n","   [172.84204   160.1177    180.4084   ]\n","   [180.45422   175.83699   194.4488   ]]\n","\n","  [[218.14795   198.80612   198.18878  ]\n","   [224.13776   216.68369   204.57654  ]\n","   [231.88776   218.22449   215.64285  ]\n","   ...\n","   [186.12698   205.98012   174.5151   ]\n","   [160.82167   169.97966   159.9341   ]\n","   [182.07164   180.85742   192.0666   ]]\n","\n","  [[209.09694   190.22449   190.76021  ]\n","   [215.4643    202.63266   198.14285  ]\n","   [163.95917   163.49998   148.83162  ]\n","   ...\n","   [169.96414   158.13217   165.27043  ]\n","   [187.84187   178.64798   194.24481  ]\n","   [185.05081   178.03563   196.27025  ]]\n","\n","  ...\n","\n","  [[ 17.260155   15.857143   24.37258  ]\n","   [ 76.47463    79.015656   81.84719  ]\n","   [152.59187   145.45944   155.95447  ]\n","   ...\n","   [ 87.75832    97.24289    83.86057  ]\n","   [ 54.699474   67.51582    64.8373   ]\n","   [ 93.50472    99.23919    98.80039  ]]\n","\n","  [[ 30.535812   23.09197    27.71953  ]\n","   [ 94.22455    89.336815   96.70408  ]\n","   [161.25021   152.07684   167.6992   ]\n","   ...\n","   [ 46.806625   66.00053    57.372944 ]\n","   [ 78.27554   102.62728    83.23983  ]\n","   [ 55.331783   63.852158   56.704197 ]]\n","\n","  [[ 97.665115   88.99657    90.48093  ]\n","   [160.35416   153.46646   156.79831  ]\n","   [191.97922   189.35666   197.84668  ]\n","   ...\n","   [131.1681    135.6222    138.2652   ]\n","   [126.27619   126.03117   123.82208  ]\n","   [109.470726  115.24576   108.88889  ]]]\n","\n","\n"," [[[131.04082   109.42857   100.081635 ]\n","   [149.94388   118.29592   132.91327  ]\n","   [126.168365   88.35204    91.234695 ]\n","   ...\n","   [127.76012   117.724144  128.24498  ]\n","   [ 15.071389   18.11725    23.117186 ]\n","   [ 43.644707   16.199236   17.632812 ]]\n","\n","  [[178.31633   147.88266   149.9592   ]\n","   [169.39287   115.239784  136.20918  ]\n","   [116.52551    91.561226   85.05102  ]\n","   ...\n","   [ 97.4949     88.63798    78.765205 ]\n","   [ 66.40766    63.943356   52.805706 ]\n","   [ 60.143665   36.99083    27.17894  ]]\n","\n","  [[ 99.04081    88.25       74.62755  ]\n","   [ 85.53061    86.95918    73.63266  ]\n","   [103.7551     90.647964   79.29592  ]\n","   ...\n","   [101.341774  107.95402    96.081505 ]\n","   [153.39224   135.80547   140.4179   ]\n","   [ 85.67887    65.93883    66.21484  ]]\n","\n","  ...\n","\n","  [[119.15834   117.01533   127.31639  ]\n","   [148.18399   156.60204   159.18881  ]\n","   [ 74.142235   59.672653   87.994    ]\n","   ...\n","   [ 16.739826   17.525562   18.122446 ]\n","   [ 16.92862    19.489819   26.249912 ]\n","   [ 17.392797   18.938766   19.081497 ]]\n","\n","  [[113.172585  107.53506   139.57063  ]\n","   [119.483376  110.192635  142.76935  ]\n","   [ 24.02533    17.249928   40.668056 ]\n","   ...\n","   [ 14.754999   16.530523   17.025398 ]\n","   [ 18.862417   20.974493   18.63787  ]\n","   [ 20.979929   18.046047   17.954105 ]]\n","\n","  [[ 11.765101   13.489536   25.096241 ]\n","   [  9.33156     8.306047   13.372472 ]\n","   [ 11.137748    9.076503   13.076503 ]\n","   ...\n","   [ 17.984825   16.852089   17.92862  ]\n","   [ 43.65891    26.582016   31.643307 ]\n","   [ 87.79954    47.128902   45.93905  ]]]\n","\n","\n"," ...\n","\n","\n"," [[[183.08673   177.44897   148.62245  ]\n","   [221.90308   209.79593   207.34186  ]\n","   [172.32143   146.43878   135.25511  ]\n","   ...\n","   [155.13684   126.586075  169.95311  ]\n","   [210.41841   178.96439   226.09195  ]\n","   [220.16896   187.61266   225.41867  ]]\n","\n","  [[231.10204   217.58673   214.88776  ]\n","   [199.69388   177.93367   154.61221  ]\n","   [213.19388   184.39798   181.56635  ]\n","   ...\n","   [216.78061   220.61836   234.70929  ]\n","   [222.8215    193.39795   224.12762  ]\n","   [214.96812   185.54018   230.98404  ]]\n","\n","  [[204.72449   195.99489   192.45918  ]\n","   [194.27042   188.83673   179.06635  ]\n","   [221.3061    189.80101   184.92857  ]\n","   ...\n","   [192.92795   142.57065   202.29063  ]\n","   [248.01024   229.21957   246.01028  ]\n","   [232.67351   198.93417   238.72461  ]]\n","\n","  ...\n","\n","  [[  9.530674   67.046394   49.199306 ]\n","   [ 13.316085   63.463615   41.183475 ]\n","   [ 19.775637   96.78611    43.015244 ]\n","   ...\n","   [206.69955   154.09744   191.82745  ]\n","   [224.73941   140.75412   193.44344  ]\n","   [156.47511    96.99468   128.3627   ]]\n","\n","  [[ 21.244709   63.458755   40.03045  ]\n","   [  4.658156   86.94361    36.841743 ]\n","   [ 17.00495    53.066074   44.418045 ]\n","   ...\n","   [220.66791   187.72334   226.27472  ]\n","   [224.06052   160.22963   210.74432  ]\n","   [193.34732   116.122086  147.32785  ]]\n","\n","  [[ 10.434065   39.761215   26.806572 ]\n","   [ 21.908516   71.473785   43.693844 ]\n","   [ 21.352873   61.47995    37.86323  ]\n","   ...\n","   [214.16876   186.134     201.72038  ]\n","   [216.75465   199.51942   218.51944  ]\n","   [200.76689   161.32748   200.7407   ]]]\n","\n","\n"," [[[187.64796   135.7296    175.2551   ]\n","   [192.89285   122.89286   182.71939  ]\n","   [174.84184   103.841835  159.31122  ]\n","   ...\n","   [ 74.489395  134.59177   132.1989   ]\n","   [ 63.93887    68.34751    97.10231  ]\n","   [ 92.62805   147.60251   141.73494  ]]\n","\n","  [[154.58672   123.341835  139.31122  ]\n","   [163.38774    90.72448   143.34183  ]\n","   [183.44897   117.46429   172.03061  ]\n","   ...\n","   [ 90.919014  138.68427   130.05159  ]\n","   [ 85.29076   118.43399   133.53062  ]\n","   [ 71.24988   170.3367    156.44373  ]]\n","\n","  [[165.54591    88.622444  153.33673  ]\n","   [165.30101    84.06122   139.99489  ]\n","   [162.84184    73.188774  142.01529  ]\n","   ...\n","   [ 59.596985  129.94905   125.73995  ]\n","   [ 57.54082   155.8826    124.70934  ]\n","   [ 65.16329   152.34125   134.38731  ]]\n","\n","  ...\n","\n","  [[207.01004   166.79547   201.50484  ]\n","   [213.44905   185.0308    210.92859  ]\n","   [224.39848   204.78142   220.31677  ]\n","   ...\n","   [ 51.181435   49.420563   36.712215 ]\n","   [ 43.98922    71.43399    43.94352  ]\n","   [ 44.33149    38.024754   36.643005 ]]\n","\n","  [[222.38266   199.87245   220.20412  ]\n","   [229.69395   213.79605   227.42863  ]\n","   [236.8928    226.04584   234.83669  ]\n","   ...\n","   [ 75.92165   134.8744     72.110275 ]\n","   [ 10.387818  143.09625    22.28578  ]\n","   [ 10.06627    41.296013    9.341999 ]]\n","\n","  [[205.54056   158.46404   210.76514  ]\n","   [232.52538   219.21394   228.57118  ]\n","   [226.75491   209.70375   221.08658  ]\n","   ...\n","   [113.81276   149.82549   107.39143  ]\n","   [  5.004927   74.57009     9.688834 ]\n","   [  2.800891   59.54361     7.2546635]]]\n","\n","\n"," [[[184.33673   162.23979   161.46939  ]\n","   [184.56122   170.92346   159.55612  ]\n","   [179.59184   155.87755   157.09694  ]\n","   ...\n","   [ 70.086296   55.43815    82.21372  ]\n","   [ 92.07151    61.204002   70.26029  ]\n","   [140.78145   112.65472   118.705605 ]]\n","\n","  [[166.07652   165.13776   155.7704   ]\n","   [168.65816   144.28061   144.89285  ]\n","   [167.46428   155.53061   150.10715  ]\n","   ...\n","   [ 94.47956    61.611813   76.14257  ]\n","   [121.107506   88.33215    99.4904   ]\n","   [171.85117   169.6673    165.96858  ]]\n","\n","  [[120.54081    95.57142   100.37755  ]\n","   [159.57144   159.7704    150.9847   ]\n","   [124.234695  108.83673   106.59694  ]\n","   ...\n","   [110.94899    74.70895    87.535835 ]\n","   [142.9185    165.38773   173.52539  ]\n","   [148.09697   154.5869    164.48975  ]]\n","\n","  ...\n","\n","  [[122.87197   111.25474    95.38764  ]\n","   [ 63.86691    71.78493    58.469036 ]\n","   [107.36743   121.71946   122.42384  ]\n","   ...\n","   [137.54097   130.19844   122.3774   ]\n","   [116.682625  124.636765  127.8004   ]\n","   [150.16792   168.76509   166.42853  ]]\n","\n","  [[ 49.28112    58.68911    47.214874 ]\n","   [ 68.75046    45.56168    51.224888 ]\n","   [ 76.709656   82.85267   125.06139  ]\n","   ...\n","   [ 94.2748     77.546      70.75072  ]\n","   [ 84.1786    112.96936   163.33696  ]\n","   [ 80.505325  100.02579   168.93336  ]]\n","\n","  [[107.02492   100.31109    97.774765 ]\n","   [108.958984   92.55173    92.00532  ]\n","   [102.04512   104.02979    94.64231  ]\n","   ...\n","   [156.34572   164.65198   164.52992  ]\n","   [132.45448   136.1573    145.82039  ]\n","   [105.624344  103.660095  143.6738   ]]]], shape=(10, 224, 224, 3), dtype=float32)\n","-------------------------------\n","tf.Tensor([1 0 1 1 0 1 1 1 1 1], shape=(10,), dtype=int32)\n"]}]}]}